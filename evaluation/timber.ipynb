{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load raw data and cleaned data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import swifter\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import string\n",
    "\n",
    "raw_data = pd.read_csv(\"../raw data/timber.csv\")\n",
    "cleaned_data = pd.read_csv(\"../cleaned data/timber.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_diff(old, new, columns):\n",
    "  old_df = old.copy().replace('', np.nan).fillna('redacted')\n",
    "  new_df = new.copy().replace('', np.nan).fillna('redacted')\n",
    "  correct = 0\n",
    "  for col in columns:\n",
    "    if col not in old_df.columns:\n",
    "      continue\n",
    "    for i in range(len(new_df[col])):\n",
    "      if new_df[col][i] == old_df[col][i]:\n",
    "        correct += 1\n",
    "  return len(old_df)*len(columns) - correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'Date', 'DeclarationNumber', 'CustomsCode', 'SenderTaxID',\n",
       "       'SenderNameEng', 'SenderAddressEng', 'RecipientNameEng',\n",
       "       'RecipientAddressEng', 'TradingCountryCode', 'DestinationCountryCode',\n",
       "       'DestinationCountryEng', 'PortUnladingEng', 'ShipmentDescriptionEng',\n",
       "       'HS', 'NetWeightKG', 'StatValue_USD', 'USD_per_KG',\n",
       "       'TradingCountryName', 'DestinationCountryName', 'HTS4',\n",
       "       'SenderCompanyKeywordsEng', 'RecipientCompanyKeywordsEng'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_cols: columns that should be numerical -> check for incorrect format\n",
    "num_cols = ['ID', 'Date', 'DeclarationNumber', 'CustomsCode', 'SenderTaxID', 'HS', 'NetWeightKG', 'StatValue_USD', 'USD_per_KG', 'HTS4']\n",
    "\n",
    "# str_cols: columns that should be string -> check for misspellings\n",
    "str_cols = list(cleaned_data.columns)\n",
    "for col in num_cols:\n",
    "  str_cols.remove(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In raw data:\n",
      "29 columns, 3087822 rows\n",
      "3.189506255932789 % of missing values.\n",
      "87.93393531103801 % of incorrect formats.\n",
      "93.19468544495116 % of misspellings.\n",
      "\n",
      "9.092597221967594 % of correct values.\n"
     ]
    }
   ],
   "source": [
    "print(f\"In raw data:\")\n",
    "print(f\"{len(list(raw_data.columns))} columns, {len(raw_data)} rows\")\n",
    "print(f\"{100*raw_data.isna().sum().sum()/(len(raw_data)*len(raw_data.columns))} % of missing values.\")\n",
    "print(f\"{100*count_diff(raw_data, cleaned_data, num_cols)/(len(raw_data)*len(num_cols))} % of incorrect formats.\")\n",
    "print(f\"{100*count_diff(raw_data, cleaned_data, str_cols)/(len(raw_data)*len(str_cols))} % of misspellings.\")\n",
    "print(f\"\\n{100-100*count_diff(raw_data, cleaned_data, list(cleaned_data.columns))/(len(raw_data)*len(list(cleaned_data.columns)))} % of correct values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In cleaned data:\n",
      "23 columns, 3087822 rows\n",
      "4.551653447696762 % of missing values.\n"
     ]
    }
   ],
   "source": [
    "print(f\"In cleaned data:\")\n",
    "print(f\"{len(cleaned_data.columns)} columns, {len(cleaned_data)} rows\")\n",
    "print(f\"{100*cleaned_data.isna().sum().sum()/(len(cleaned_data)*len(cleaned_data.columns))} % of missing values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import dateutil\n",
    "from gensim.models import KeyedVectors\n",
    "import nltk\n",
    "from sklearn.cluster import KMeans\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import langdetect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TradeSleuth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 3087822/3087822 [01:53<00:00, 27184.77it/s]\n",
      "Pandas Apply: 100%|██████████| 3087822/3087822 [00:09<00:00, 325333.75it/s]\n",
      "Pandas Apply: 100%|██████████| 3087822/3087822 [00:04<00:00, 658773.32it/s]\n",
      "Pandas Apply: 100%|██████████| 3087822/3087822 [00:03<00:00, 940885.34it/s] \n",
      "Pandas Apply: 100%|██████████| 3087822/3087822 [00:02<00:00, 1124147.22it/s]\n",
      "Pandas Apply: 100%|██████████| 3087822/3087822 [00:12<00:00, 253351.31it/s]\n",
      "Pandas Apply: 100%|██████████| 3087822/3087822 [00:14<00:00, 205891.81it/s]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../tradesleuth/timber.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns dropped correctly: True\n",
      "\n",
      "Before cleaning: 100.0 % of incorrect dates.\n",
      "Clean Dates: 0.0 % of incorrect dates.\n",
      "\n",
      "Before cleaning: 82.4726943457233 % of misspelled TradingCountryCode.\n",
      "Clean TradingCountryCode: 6.477057291514861e-05 % of misspelled TradingCountryCode.\n",
      "Add new TradingCountryName: 6.477057291514861e-05 % of misspelled TradingCountryName.\n",
      "\n",
      "Before cleaning: 80.16397965944928 % of misspelled DestinationCountryCode.\n",
      "Clean DestinationCountryCode: 17.923118625361177 % of misspelled DestinationCountryCode.\n",
      "Add new DestinationCountryName: 17.923118625361177 % of misspelled DestinationCountryName.\n",
      "\n",
      "Before cleaning: 92.7261998910559 % of incorrect HS.\n",
      "Clean HS: 0.0 % of incorrect HS.\n",
      "Add new HTS4: 0.0 % of incorrect HTS4.\n",
      "\n",
      "Before cleaning: 96.14647476441323 % of misspelled PortUnladingEng.\n",
      "Clean PortUnladingEng: 0.0 % of misspelled PortUnladingEng.\n",
      "\n",
      "Before cleaning: 99.94614326862106 % of incorrect NetWeightKG.\n",
      "Clean NetWeightKG: 0.0 % of incorrect NetWeightKG.\n",
      "\n",
      "Before cleaning: 99.99731202122402 % of incorrect StatValue_USD.\n",
      "Clean StatValue_USD: 0.0008744027343545062 % of incorrect StatValue_USD.\n",
      "\n",
      "Before cleaning: 97.1600694599624 % of incorrect USD_per_KG.\n",
      "Clean USD_per_KG: 0.0 % of incorrect USD_per_KG.\n",
      "\n",
      "Before cleaning: 99.99601660976572 % of misspelled SenderNameEng.\n",
      "Clean strings: 0.0 % of misspelled SenderNameEng.\n",
      "\n",
      "Before cleaning: 100.0 % of misspelled SenderCompanyKeywordsEng.\n",
      "Clean strings: 0.0 % of misspelled SenderCompanyKeywordsEng.\n",
      "\n",
      "Before cleaning: 99.95851444804785 % of misspelled RecipientNameEng.\n",
      "Clean strings: 0.0 % of misspelled RecipientNameEng.\n",
      "\n",
      "Before cleaning: 100.0 % of misspelled RecipientCompanyKeywordsEng.\n",
      "Clean strings: 0.0 % of misspelled RecipientCompanyKeywordsEng.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"\\nColumns dropped correctly: {list(df.columns)==list(cleaned_data.columns)}\")\n",
    "\n",
    "print(f\"\\nBefore cleaning: {100*count_diff(raw_data, cleaned_data, ['Date'])/len(raw_data)} % of incorrect dates.\")\n",
    "print(f\"Clean Dates: {100*count_diff(df, cleaned_data, ['Date'])/len(df)} % of incorrect dates.\")\n",
    "\n",
    "print(f\"\\nBefore cleaning: {100*count_diff(raw_data, cleaned_data, ['TradingCountryCode'])/len(raw_data)} % of misspelled TradingCountryCode.\")\n",
    "print(f\"Clean TradingCountryCode: {100*count_diff(df, cleaned_data, ['TradingCountryCode'])/len(df)} % of misspelled TradingCountryCode.\")\n",
    "\n",
    "print(f\"Add new TradingCountryName: {100*count_diff(df, cleaned_data, ['TradingCountryName'])/len(df)} % of misspelled TradingCountryName.\")\n",
    "\n",
    "print(f\"\\nBefore cleaning: {100*count_diff(raw_data, cleaned_data, ['DestinationCountryCode'])/len(raw_data)} % of misspelled DestinationCountryCode.\")\n",
    "print(f\"Clean DestinationCountryCode: {100*count_diff(df, cleaned_data, ['DestinationCountryCode'])/len(df)} % of misspelled DestinationCountryCode.\")\n",
    "\n",
    "print(f\"Add new DestinationCountryName: {100*count_diff(df, cleaned_data, ['DestinationCountryName'])/len(df)} % of misspelled DestinationCountryName.\")\n",
    "\n",
    "print(f\"\\nBefore cleaning: {100*count_diff(raw_data, cleaned_data, ['HS'])/len(raw_data)} % of incorrect HS.\")\n",
    "print(f\"Clean HS: {100*count_diff(df, cleaned_data, ['HS'])/len(df)} % of incorrect HS.\")\n",
    "\n",
    "print(f\"Add new HTS4: {100*count_diff(df, cleaned_data, ['HTS4'])/len(df)} % of incorrect HTS4.\")\n",
    "\n",
    "print(f\"\\nBefore cleaning: {100*count_diff(raw_data, cleaned_data, ['PortUnladingEng'])/len(raw_data)} % of misspelled PortUnladingEng.\")\n",
    "print(f\"Clean PortUnladingEng: {100*count_diff(df, cleaned_data, ['PortUnladingEng'])/len(df)} % of misspelled PortUnladingEng.\")\n",
    "\n",
    "print(f\"\\nBefore cleaning: {100*count_diff(raw_data, cleaned_data, ['NetWeightKG'])/len(raw_data)} % of incorrect NetWeightKG.\")\n",
    "print(f\"Clean NetWeightKG: {100*count_diff(df, cleaned_data, ['NetWeightKG'])/len(df)} % of incorrect NetWeightKG.\")\n",
    "\n",
    "print(f\"\\nBefore cleaning: {100*count_diff(raw_data, cleaned_data, ['StatValue_USD'])/len(raw_data)} % of incorrect StatValue_USD.\")\n",
    "print(f\"Clean StatValue_USD: {100*count_diff(df, cleaned_data, ['StatValue_USD'])/len(df)} % of incorrect StatValue_USD.\")\n",
    "\n",
    "print(f\"\\nBefore cleaning: {100*count_diff(raw_data, cleaned_data, ['USD_per_KG'])/len(raw_data)} % of incorrect USD_per_KG.\")\n",
    "print(f\"Clean USD_per_KG: {100*count_diff(df, cleaned_data, ['USD_per_KG'])/len(df)} % of incorrect USD_per_KG.\")\n",
    "\n",
    "print(f\"\\nBefore cleaning: {100*count_diff(raw_data, cleaned_data, ['SenderNameEng'])/len(df)} % of misspelled SenderNameEng.\")\n",
    "print(f\"Clean strings: {100*count_diff(df, cleaned_data, ['SenderNameEng'])/len(df)} % of misspelled SenderNameEng.\")\n",
    "\n",
    "print(f\"\\nBefore cleaning: {100*count_diff(raw_data, cleaned_data, ['SenderCompanyKeywordsEng'])/len(raw_data)} % of misspelled SenderCompanyKeywordsEng.\")\n",
    "print(f\"Clean strings: {100*count_diff(df, cleaned_data, ['SenderCompanyKeywordsEng'])/len(df)} % of misspelled SenderCompanyKeywordsEng.\")\n",
    "\n",
    "print(f\"\\nBefore cleaning: {100*count_diff(raw_data, cleaned_data, ['RecipientNameEng'])/len(df)} % of misspelled RecipientNameEng.\")\n",
    "print(f\"Clean strings: {100*count_diff(df, cleaned_data, ['RecipientNameEng'])/len(df)} % of misspelled RecipientNameEng.\")\n",
    "\n",
    "print(f\"\\nBefore cleaning: {100*count_diff(raw_data, cleaned_data, ['RecipientCompanyKeywordsEng'])/len(raw_data)} % of misspelled RecipientCompanyKeywordsEng.\")\n",
    "print(f\"Clean strings: {100*count_diff(df, cleaned_data, ['RecipientCompanyKeywordsEng'])/len(df)} % of misspelled RecipientCompanyKeywordsEng.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean data by TradeSleuth:\n",
      "\n",
      "23 columns, 3087822 rows\n",
      "4.416985570214639 % of missing values.\n",
      "0.6251299459619111 % of incorrect formats.\n",
      "2.7574128301437066 % of misspellings.\n",
      "\n",
      "98.16966668471794 % of correct values.\n",
      "\n",
      "Average time to generate correct code: 94.08219697532695 s.\n",
      "Average # of revises to generate correct code: 1.2916666666666667.\n",
      "Accepted first-time codes: 18/24.\n"
     ]
    }
   ],
   "source": [
    "# After exiting, you will see the consumed time and iterations for each prompt, paste them here\n",
    "print(f\"Clean data by TradeSleuth:\\n\")\n",
    "print(f\"{len(list(df.columns))} columns, {len(df)} rows\")\n",
    "print(f\"{100*df.isna().sum().sum()/(len(df)*len(df.columns))} % of missing values.\")\n",
    "print(f\"{100*count_diff(df, cleaned_data, num_cols)/(len(df)*len(num_cols))} % of incorrect formats.\")\n",
    "print(f\"{100*count_diff(df, cleaned_data, str_cols)/(len(df)*len(str_cols))} % of misspellings.\")\n",
    "print(f\"\\n{100-100*count_diff(df, cleaned_data, list(cleaned_data.columns))/(len(df)*len(cleaned_data.columns))} % of correct values.\")\n",
    "\n",
    "Time = [79.65075605700258, 59.51330720199621, 73.73047116296948, 70.54568276699865, 62.25828658399405, 130.07804629698512, 89.5422365150007, 59.6199929129798, 61.813277503999416, 42.0794862699986, 99.94885707698995, 106.93385059898719, 187.995986814989, 114.95132225798443, 158.38310202999855, 78.77653913199902, 9.798073577985633, 65.30802252300782, 82.57840017799754, 101.65643327499856, 104.15271733998088, 145.36316845499096, 100.75866600999143, 172.53604486602126]\n",
    "Iteration = [1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 1, 3, 1, 1]\n",
    "\n",
    "total_time = np.sum(Time)\n",
    "total_iteration = np.sum(Iteration)\n",
    "first_time_cnt = 0\n",
    "for i in Iteration:\n",
    "  if Iteration[i] == 1:\n",
    "    first_time_cnt += 1\n",
    "print(f\"\\nAverage time to generate correct code: {total_time/len(Time)} s.\")\n",
    "print(f\"Average # of revises to generate correct code: {total_iteration/len(Iteration)}.\")\n",
    "print(f\"Accepted first-time codes: {first_time_cnt}/{len(Iteration)}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../baseline_1/timber.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns dropped correctly: True\n",
      "\n",
      "Before cleaning: 100.0 % of incorrect dates.\n",
      "Clean Dates: 54.969036427617915 % of incorrect dates.\n",
      "\n",
      "Before cleaning: 82.4726943457233 % of misspelled TradingCountryCode.\n",
      "Clean TradingCountryCode: 99.6489434947999 % of misspelled TradingCountryCode.\n",
      "Add new TradingCountryName: 99.6489434947999 % of misspelled TradingCountryName.\n",
      "\n",
      "Before cleaning: 80.16397965944928 % of misspelled DestinationCountryCode.\n",
      "Clean DestinationCountryCode: 64.01881326060894 % of misspelled DestinationCountryCode.\n",
      "Add new DestinationCountryName: 64.45222554927065 % of misspelled DestinationCountryName.\n",
      "\n",
      "Before cleaning: 92.7261998910559 % of incorrect HS.\n",
      "Clean HS: 65.363774207192 % of incorrect HS.\n",
      "Add new HTS4: 43.395409450415215 % of incorrect HTS4.\n",
      "\n",
      "Before cleaning: 96.14647476441323 % of misspelled PortUnladingEng.\n",
      "Clean PortUnladingEng: 84.0574683385247 % of misspelled PortUnladingEng.\n",
      "\n",
      "Before cleaning: 99.94614326862106 % of incorrect NetWeightKG.\n",
      "Clean NetWeightKG: 86.12915511321572 % of incorrect NetWeightKG.\n",
      "\n",
      "Before cleaning: 99.99731202122402 % of incorrect StatValue_USD.\n",
      "Clean StatValue_USD: 86.4407663395105 % of incorrect StatValue_USD.\n",
      "\n",
      "Before cleaning: 97.1600694599624 % of incorrect USD_per_KG.\n",
      "Clean USD_per_KG: 79.9271784448715 % of incorrect USD_per_KG.\n",
      "\n",
      "Before cleaning: 99.99601660976572 % of misspelled SenderNameEng.\n",
      "Clean strings: 98.07394985850868 % of misspelled SenderNameEng.\n",
      "\n",
      "Before cleaning: 100.0 % of misspelled SenderCompanyKeywordsEng.\n",
      "Clean strings: 35.19383565503452 % of misspelled SenderCompanyKeywordsEng.\n",
      "\n",
      "Before cleaning: 99.95851444804785 % of misspelled RecipientNameEng.\n",
      "Clean strings: 94.65373975572426 % of misspelled RecipientNameEng.\n",
      "\n",
      "Before cleaning: 100.0 % of misspelled RecipientCompanyKeywordsEng.\n",
      "Clean strings: 46.82255000450156 % of misspelled RecipientCompanyKeywordsEng.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"\\nColumns dropped correctly: {list(df.columns)==list(cleaned_data.columns)}\")\n",
    "\n",
    "print(f\"\\nBefore cleaning: {100*count_diff(raw_data, cleaned_data, ['Date'])/len(raw_data)} % of incorrect dates.\")\n",
    "print(f\"Clean Dates: {100*count_diff(df, cleaned_data, ['Date'])/len(df)} % of incorrect dates.\")\n",
    "\n",
    "print(f\"\\nBefore cleaning: {100*count_diff(raw_data, cleaned_data, ['TradingCountryCode'])/len(raw_data)} % of misspelled TradingCountryCode.\")\n",
    "print(f\"Clean TradingCountryCode: {100*count_diff(df, cleaned_data, ['TradingCountryCode'])/len(df)} % of misspelled TradingCountryCode.\")\n",
    "\n",
    "print(f\"Add new TradingCountryName: {100*count_diff(df, cleaned_data, ['TradingCountryName'])/len(df)} % of misspelled TradingCountryName.\")\n",
    "\n",
    "print(f\"\\nBefore cleaning: {100*count_diff(raw_data, cleaned_data, ['DestinationCountryCode'])/len(raw_data)} % of misspelled DestinationCountryCode.\")\n",
    "print(f\"Clean DestinationCountryCode: {100*count_diff(df, cleaned_data, ['DestinationCountryCode'])/len(df)} % of misspelled DestinationCountryCode.\")\n",
    "\n",
    "print(f\"Add new DestinationCountryName: {100*count_diff(df, cleaned_data, ['DestinationCountryName'])/len(df)} % of misspelled DestinationCountryName.\")\n",
    "\n",
    "print(f\"\\nBefore cleaning: {100*count_diff(raw_data, cleaned_data, ['HS'])/len(raw_data)} % of incorrect HS.\")\n",
    "print(f\"Clean HS: {100*count_diff(df, cleaned_data, ['HS'])/len(df)} % of incorrect HS.\")\n",
    "\n",
    "print(f\"Add new HTS4: {100*count_diff(df, cleaned_data, ['HTS4'])/len(df)} % of incorrect HTS4.\")\n",
    "\n",
    "print(f\"\\nBefore cleaning: {100*count_diff(raw_data, cleaned_data, ['PortUnladingEng'])/len(raw_data)} % of misspelled PortUnladingEng.\")\n",
    "print(f\"Clean PortUnladingEng: {100*count_diff(df, cleaned_data, ['PortUnladingEng'])/len(df)} % of misspelled PortUnladingEng.\")\n",
    "\n",
    "print(f\"\\nBefore cleaning: {100*count_diff(raw_data, cleaned_data, ['NetWeightKG'])/len(raw_data)} % of incorrect NetWeightKG.\")\n",
    "print(f\"Clean NetWeightKG: {100*count_diff(df, cleaned_data, ['NetWeightKG'])/len(df)} % of incorrect NetWeightKG.\")\n",
    "\n",
    "print(f\"\\nBefore cleaning: {100*count_diff(raw_data, cleaned_data, ['StatValue_USD'])/len(raw_data)} % of incorrect StatValue_USD.\")\n",
    "print(f\"Clean StatValue_USD: {100*count_diff(df, cleaned_data, ['StatValue_USD'])/len(df)} % of incorrect StatValue_USD.\")\n",
    "\n",
    "print(f\"\\nBefore cleaning: {100*count_diff(raw_data, cleaned_data, ['USD_per_KG'])/len(raw_data)} % of incorrect USD_per_KG.\")\n",
    "print(f\"Clean USD_per_KG: {100*count_diff(df, cleaned_data, ['USD_per_KG'])/len(df)} % of incorrect USD_per_KG.\")\n",
    "\n",
    "print(f\"\\nBefore cleaning: {100*count_diff(raw_data, cleaned_data, ['SenderNameEng'])/len(df)} % of misspelled SenderNameEng.\")\n",
    "print(f\"Clean strings: {100*count_diff(df, cleaned_data, ['SenderNameEng'])/len(df)} % of misspelled SenderNameEng.\")\n",
    "\n",
    "print(f\"\\nBefore cleaning: {100*count_diff(raw_data, cleaned_data, ['SenderCompanyKeywordsEng'])/len(raw_data)} % of misspelled SenderCompanyKeywordsEng.\")\n",
    "print(f\"Clean strings: {100*count_diff(df, cleaned_data, ['SenderCompanyKeywordsEng'])/len(df)} % of misspelled SenderCompanyKeywordsEng.\")\n",
    "\n",
    "print(f\"\\nBefore cleaning: {100*count_diff(raw_data, cleaned_data, ['RecipientNameEng'])/len(df)} % of misspelled RecipientNameEng.\")\n",
    "print(f\"Clean strings: {100*count_diff(df, cleaned_data, ['RecipientNameEng'])/len(df)} % of misspelled RecipientNameEng.\")\n",
    "\n",
    "print(f\"\\nBefore cleaning: {100*count_diff(raw_data, cleaned_data, ['RecipientCompanyKeywordsEng'])/len(raw_data)} % of misspelled RecipientCompanyKeywordsEng.\")\n",
    "print(f\"Clean strings: {100*count_diff(df, cleaned_data, ['RecipientCompanyKeywordsEng'])/len(df)} % of misspelled RecipientCompanyKeywordsEng.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean data by baseline-1:\n",
      "\n",
      "23 columns, 3087822 rows\n",
      "8.6779993766818 % of missing values.\n",
      "64.85602797052421 % of incorrect formats.\n",
      "74.69186770082352 % of misspellings.\n",
      "\n",
      "29.584584355828355 % of correct values.\n",
      "\n",
      "Average time to generate correct code: 42.71154210596561 s.\n",
      "Average # of revises to generate correct code: 1.5.\n",
      "Accepted first-time codes: 15/24.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Clean data by baseline-1:\\n\")\n",
    "print(f\"{len(list(df.columns))} columns, {len(df)} rows\")\n",
    "print(f\"{100*df.isna().sum().sum()/(len(df)*len(df.columns))} % of missing values.\")\n",
    "print(f\"{100*count_diff(df, cleaned_data, num_cols)/(len(df)*len(num_cols))} % of incorrect formats.\")\n",
    "print(f\"{100*count_diff(df, cleaned_data, str_cols)/(len(df)*len(str_cols))} % of misspellings.\")\n",
    "print(f\"\\n{100-100*count_diff(df, cleaned_data, list(cleaned_data.columns))/(len(df)*len(cleaned_data.columns))} % of correct values.\")\n",
    "\n",
    "Time = [36.93427055608481, 107.01350814756006, 33.00332809984684, 3.4735623924061656, 18.158847643993795, 5.664895256981254, 8.665143555030227, 61.78852176852524, 32.51175516564399, 4.910342332907021, 6.8554142117500305, 13.825508235022426, 81.27918144781142, 77.9169830866158, 32.45436257899928, 38.75309891100005, 56.48922213700098, 32.20490395100023, 57.67274600099881, 29.618397694999658, 83.40509776999897, 31.575577438001346, 48.39258606599833, 122.50975609499801]\n",
    "Iteration = [1, 3, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 2, 1, 1, 2, 1, 3, 1, 2, 1, 2, 3]\n",
    "\n",
    "total_time = np.sum(Time)\n",
    "total_iteration = np.sum(Iteration)\n",
    "first_time_cnt = 0\n",
    "for i in Iteration:\n",
    "  if Iteration[i] == 1:\n",
    "    first_time_cnt += 1\n",
    "print(f\"\\nAverage time to generate correct code: {total_time/len(Time)} s.\")\n",
    "print(f\"Average # of revises to generate correct code: {total_iteration/len(Iteration)}.\")\n",
    "print(f\"Accepted first-time codes: {first_time_cnt}/{len(Iteration)}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../baseline_2/timber.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns dropped correctly: True\n",
      "\n",
      "Before cleaning: 100.0 % of incorrect dates.\n",
      "Clean Dates: 0.0 % of incorrect dates.\n",
      "\n",
      "Before cleaning: 82.4726943457233 % of misspelled TradingCountryCode.\n",
      "Clean TradingCountryCode: 18.65680729005752 % of misspelled TradingCountryCode.\n",
      "Add new TradingCountryName: 18.65680729005752 % of misspelled TradingCountryName.\n",
      "\n",
      "Before cleaning: 80.16397965944928 % of misspelled DestinationCountryCode.\n",
      "Clean DestinationCountryCode: 0.8124172960747089 % of misspelled DestinationCountryCode.\n",
      "Add new DestinationCountryName: 0.8124172960747089 % of misspelled DestinationCountryName.\n",
      "\n",
      "Before cleaning: 92.7261998910559 % of incorrect HS.\n",
      "Clean HS: 0.0 % of incorrect HS.\n",
      "Add new HTS4: 0.0 % of incorrect HTS4.\n",
      "\n",
      "Before cleaning: 96.14647476441323 % of misspelled PortUnladingEng.\n",
      "Clean PortUnladingEng: 0.0 % of misspelled PortUnladingEng.\n",
      "\n",
      "Before cleaning: 99.94614326862106 % of incorrect NetWeightKG.\n",
      "Clean NetWeightKG: 0.0 % of incorrect NetWeightKG.\n",
      "\n",
      "Before cleaning: 99.99731202122402 % of incorrect StatValue_USD.\n",
      "Clean StatValue_USD: 0.0008744027343545062 % of incorrect StatValue_USD.\n",
      "\n",
      "Before cleaning: 97.1600694599624 % of incorrect USD_per_KG.\n",
      "Clean USD_per_KG: 0.0 % of incorrect USD_per_KG.\n",
      "\n",
      "Before cleaning: 99.99601660976572 % of misspelled SenderNameEng.\n",
      "Clean strings: 13.60525315254571 % of misspelled SenderNameEng.\n",
      "\n",
      "Before cleaning: 100.0 % of misspelled SenderCompanyKeywordsEng.\n",
      "Clean strings: 0.0 % of misspelled SenderCompanyKeywordsEng.\n",
      "\n",
      "Before cleaning: 99.95851444804785 % of misspelled RecipientNameEng.\n",
      "Clean strings: 0.0 % of misspelled RecipientNameEng.\n",
      "\n",
      "Before cleaning: 100.0 % of misspelled RecipientCompanyKeywordsEng.\n",
      "Clean strings: 0.0 % of misspelled RecipientCompanyKeywordsEng.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"\\nColumns dropped correctly: {list(df.columns)==list(cleaned_data.columns)}\")\n",
    "\n",
    "print(f\"\\nBefore cleaning: {100*count_diff(raw_data, cleaned_data, ['Date'])/len(raw_data)} % of incorrect dates.\")\n",
    "print(f\"Clean Dates: {100*count_diff(df, cleaned_data, ['Date'])/len(df)} % of incorrect dates.\")\n",
    "\n",
    "print(f\"\\nBefore cleaning: {100*count_diff(raw_data, cleaned_data, ['TradingCountryCode'])/len(raw_data)} % of misspelled TradingCountryCode.\")\n",
    "print(f\"Clean TradingCountryCode: {100*count_diff(df, cleaned_data, ['TradingCountryCode'])/len(df)} % of misspelled TradingCountryCode.\")\n",
    "\n",
    "print(f\"Add new TradingCountryName: {100*count_diff(df, cleaned_data, ['TradingCountryName'])/len(df)} % of misspelled TradingCountryName.\")\n",
    "\n",
    "print(f\"\\nBefore cleaning: {100*count_diff(raw_data, cleaned_data, ['DestinationCountryCode'])/len(raw_data)} % of misspelled DestinationCountryCode.\")\n",
    "print(f\"Clean DestinationCountryCode: {100*count_diff(df, cleaned_data, ['DestinationCountryCode'])/len(df)} % of misspelled DestinationCountryCode.\")\n",
    "\n",
    "print(f\"Add new DestinationCountryName: {100*count_diff(df, cleaned_data, ['DestinationCountryName'])/len(df)} % of misspelled DestinationCountryName.\")\n",
    "\n",
    "print(f\"\\nBefore cleaning: {100*count_diff(raw_data, cleaned_data, ['HS'])/len(raw_data)} % of incorrect HS.\")\n",
    "print(f\"Clean HS: {100*count_diff(df, cleaned_data, ['HS'])/len(df)} % of incorrect HS.\")\n",
    "\n",
    "print(f\"Add new HTS4: {100*count_diff(df, cleaned_data, ['HTS4'])/len(df)} % of incorrect HTS4.\")\n",
    "\n",
    "print(f\"\\nBefore cleaning: {100*count_diff(raw_data, cleaned_data, ['PortUnladingEng'])/len(raw_data)} % of misspelled PortUnladingEng.\")\n",
    "print(f\"Clean PortUnladingEng: {100*count_diff(df, cleaned_data, ['PortUnladingEng'])/len(df)} % of misspelled PortUnladingEng.\")\n",
    "\n",
    "print(f\"\\nBefore cleaning: {100*count_diff(raw_data, cleaned_data, ['NetWeightKG'])/len(raw_data)} % of incorrect NetWeightKG.\")\n",
    "print(f\"Clean NetWeightKG: {100*count_diff(df, cleaned_data, ['NetWeightKG'])/len(df)} % of incorrect NetWeightKG.\")\n",
    "\n",
    "print(f\"\\nBefore cleaning: {100*count_diff(raw_data, cleaned_data, ['StatValue_USD'])/len(raw_data)} % of incorrect StatValue_USD.\")\n",
    "print(f\"Clean StatValue_USD: {100*count_diff(df, cleaned_data, ['StatValue_USD'])/len(df)} % of incorrect StatValue_USD.\")\n",
    "\n",
    "print(f\"\\nBefore cleaning: {100*count_diff(raw_data, cleaned_data, ['USD_per_KG'])/len(raw_data)} % of incorrect USD_per_KG.\")\n",
    "print(f\"Clean USD_per_KG: {100*count_diff(df, cleaned_data, ['USD_per_KG'])/len(df)} % of incorrect USD_per_KG.\")\n",
    "\n",
    "print(f\"\\nBefore cleaning: {100*count_diff(raw_data, cleaned_data, ['SenderNameEng'])/len(df)} % of misspelled SenderNameEng.\")\n",
    "print(f\"Clean strings: {100*count_diff(df, cleaned_data, ['SenderNameEng'])/len(df)} % of misspelled SenderNameEng.\")\n",
    "\n",
    "print(f\"\\nBefore cleaning: {100*count_diff(raw_data, cleaned_data, ['SenderCompanyKeywordsEng'])/len(raw_data)} % of misspelled SenderCompanyKeywordsEng.\")\n",
    "print(f\"Clean strings: {100*count_diff(df, cleaned_data, ['SenderCompanyKeywordsEng'])/len(df)} % of misspelled SenderCompanyKeywordsEng.\")\n",
    "\n",
    "print(f\"\\nBefore cleaning: {100*count_diff(raw_data, cleaned_data, ['RecipientNameEng'])/len(df)} % of misspelled RecipientNameEng.\")\n",
    "print(f\"Clean strings: {100*count_diff(df, cleaned_data, ['RecipientNameEng'])/len(df)} % of misspelled RecipientNameEng.\")\n",
    "\n",
    "print(f\"\\nBefore cleaning: {100*count_diff(raw_data, cleaned_data, ['RecipientCompanyKeywordsEng'])/len(raw_data)} % of misspelled RecipientCompanyKeywordsEng.\")\n",
    "print(f\"Clean strings: {100*count_diff(df, cleaned_data, ['RecipientCompanyKeywordsEng'])/len(df)} % of misspelled RecipientCompanyKeywordsEng.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean data by baseline-2:\n",
      "\n",
      "23 columns, 3087822 rows\n",
      "4.75665794319694 % of missing values.\n",
      "0.6251299459619111 % of incorrect formats.\n",
      "4.041823255754629 % of misspellings.\n",
      "\n",
      "97.44369557459004 % of correct values.\n",
      "\n",
      "Average time to generate correct code: 134.64745176657257 s.\n",
      "Average # of revises to generate correct code: 2.125.\n",
      "Accepted first-time codes: 5/24.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Clean data by baseline-2:\\n\")\n",
    "print(f\"{len(list(df.columns))} columns, {len(df)} rows\")\n",
    "print(f\"{100*df.isna().sum().sum()/(len(df)*len(df.columns))} % of missing values.\")\n",
    "print(f\"{100*count_diff(df, cleaned_data, num_cols)/(len(df)*len(num_cols))} % of incorrect formats.\")\n",
    "print(f\"{100*count_diff(df, cleaned_data, str_cols)/(len(df)*len(str_cols))} % of misspellings.\")\n",
    "print(f\"\\n{100-100*count_diff(df, cleaned_data, list(cleaned_data.columns))/(len(df)*len(cleaned_data.columns))} % of correct values.\")\n",
    "\n",
    "Time = [70.31692368071526, 186.8816757388413, 168.90672597661614, 167.44252010062337, 79.34907004702836, 203.12355579063296, 296.4537397371605, 227.95822145789862, 142.40654882136732, 137.60550732538104, 179.05404731351882, 71.52330657374114, 91.02093854639679, 154.09032074455172, 75.03718110453337, 339.73870580643415, 91.82672706991434, 87.93194920290262, 71.70418223086745, 54.12616850901395, 69.1190603254363, 101.66071887407452, 75.96594125032425, 88.29510616976768]\n",
    "Iteration = [1, 2, 2, 2, 1, 3, 3, 3, 2, 2, 2, 1, 1, 3, 1, 2, 4, 4, 2, 2, 2, 2, 2, 2]\n",
    "\n",
    "applied = [0, 2, 3, 7, 8, 9, 10, 11, 14, 16, 17, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32]\n",
    "\n",
    "total_time = np.sum(Time)\n",
    "total_iteration = np.sum(Iteration)\n",
    "first_time_cnt = 0\n",
    "for i in Iteration:\n",
    "  if Iteration[i] == 1:\n",
    "    first_time_cnt += 1\n",
    "print(f\"\\nAverage time to generate correct code: {total_time/len(Time)} s.\")\n",
    "print(f\"Average # of revises to generate correct code: {total_iteration/len(Iteration)}.\")\n",
    "print(f\"Accepted first-time codes: {first_time_cnt}/{len(Iteration)}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../baseline_3/timber.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns dropped correctly: True\n",
      "\n",
      "Before cleaning: 100.0 % of incorrect dates.\n",
      "Clean Dates: 0.0 % of incorrect dates.\n",
      "\n",
      "Before cleaning: 82.4726943457233 % of misspelled TradingCountryCode.\n",
      "Clean TradingCountryCode: 6.477057291514861e-05 % of misspelled TradingCountryCode.\n",
      "Add new TradingCountryName: 6.477057291514861e-05 % of misspelled TradingCountryName.\n",
      "\n",
      "Before cleaning: 80.16397965944928 % of misspelled DestinationCountryCode.\n",
      "Clean DestinationCountryCode: 0.22663223463010498 % of misspelled DestinationCountryCode.\n",
      "Add new DestinationCountryName: 0.22663223463010498 % of misspelled DestinationCountryName.\n",
      "\n",
      "Before cleaning: 92.7261998910559 % of incorrect HS.\n",
      "Clean HS: 0.0 % of incorrect HS.\n",
      "Add new HTS4: 0.0 % of incorrect HTS4.\n",
      "\n",
      "Before cleaning: 96.14647476441323 % of misspelled PortUnladingEng.\n",
      "Clean PortUnladingEng: 0.0 % of misspelled PortUnladingEng.\n",
      "\n",
      "Before cleaning: 99.94614326862106 % of incorrect NetWeightKG.\n",
      "Clean NetWeightKG: 91.5089665142615 % of incorrect NetWeightKG.\n",
      "\n",
      "Before cleaning: 99.99731202122402 % of incorrect StatValue_USD.\n",
      "Clean StatValue_USD: 0.17714751692293143 % of incorrect StatValue_USD.\n",
      "\n",
      "Before cleaning: 97.1600694599624 % of incorrect USD_per_KG.\n",
      "Clean USD_per_KG: 30.12958648523134 % of incorrect USD_per_KG.\n",
      "\n",
      "Before cleaning: 99.99601660976572 % of misspelled SenderNameEng.\n",
      "Clean strings: 88.37076748594964 % of misspelled SenderNameEng.\n",
      "\n",
      "Before cleaning: 100.0 % of misspelled SenderCompanyKeywordsEng.\n",
      "Clean strings: 0.0 % of misspelled SenderCompanyKeywordsEng.\n",
      "\n",
      "Before cleaning: 99.95851444804785 % of misspelled RecipientNameEng.\n",
      "Clean strings: 0.0 % of misspelled RecipientNameEng.\n",
      "\n",
      "Before cleaning: 100.0 % of misspelled RecipientCompanyKeywordsEng.\n",
      "Clean strings: 0.0 % of misspelled RecipientCompanyKeywordsEng.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"\\nColumns dropped correctly: {list(df.columns)==list(cleaned_data.columns)}\")\n",
    "\n",
    "print(f\"\\nBefore cleaning: {100*count_diff(raw_data, cleaned_data, ['Date'])/len(raw_data)} % of incorrect dates.\")\n",
    "print(f\"Clean Dates: {100*count_diff(df, cleaned_data, ['Date'])/len(df)} % of incorrect dates.\")\n",
    "\n",
    "print(f\"\\nBefore cleaning: {100*count_diff(raw_data, cleaned_data, ['TradingCountryCode'])/len(raw_data)} % of misspelled TradingCountryCode.\")\n",
    "print(f\"Clean TradingCountryCode: {100*count_diff(df, cleaned_data, ['TradingCountryCode'])/len(df)} % of misspelled TradingCountryCode.\")\n",
    "\n",
    "print(f\"Add new TradingCountryName: {100*count_diff(df, cleaned_data, ['TradingCountryName'])/len(df)} % of misspelled TradingCountryName.\")\n",
    "\n",
    "print(f\"\\nBefore cleaning: {100*count_diff(raw_data, cleaned_data, ['DestinationCountryCode'])/len(raw_data)} % of misspelled DestinationCountryCode.\")\n",
    "print(f\"Clean DestinationCountryCode: {100*count_diff(df, cleaned_data, ['DestinationCountryCode'])/len(df)} % of misspelled DestinationCountryCode.\")\n",
    "\n",
    "print(f\"Add new DestinationCountryName: {100*count_diff(df, cleaned_data, ['DestinationCountryName'])/len(df)} % of misspelled DestinationCountryName.\")\n",
    "\n",
    "print(f\"\\nBefore cleaning: {100*count_diff(raw_data, cleaned_data, ['HS'])/len(raw_data)} % of incorrect HS.\")\n",
    "print(f\"Clean HS: {100*count_diff(df, cleaned_data, ['HS'])/len(df)} % of incorrect HS.\")\n",
    "\n",
    "print(f\"Add new HTS4: {100*count_diff(df, cleaned_data, ['HTS4'])/len(df)} % of incorrect HTS4.\")\n",
    "\n",
    "print(f\"\\nBefore cleaning: {100*count_diff(raw_data, cleaned_data, ['PortUnladingEng'])/len(raw_data)} % of misspelled PortUnladingEng.\")\n",
    "print(f\"Clean PortUnladingEng: {100*count_diff(df, cleaned_data, ['PortUnladingEng'])/len(df)} % of misspelled PortUnladingEng.\")\n",
    "\n",
    "print(f\"\\nBefore cleaning: {100*count_diff(raw_data, cleaned_data, ['NetWeightKG'])/len(raw_data)} % of incorrect NetWeightKG.\")\n",
    "print(f\"Clean NetWeightKG: {100*count_diff(df, cleaned_data, ['NetWeightKG'])/len(df)} % of incorrect NetWeightKG.\")\n",
    "\n",
    "print(f\"\\nBefore cleaning: {100*count_diff(raw_data, cleaned_data, ['StatValue_USD'])/len(raw_data)} % of incorrect StatValue_USD.\")\n",
    "print(f\"Clean StatValue_USD: {100*count_diff(df, cleaned_data, ['StatValue_USD'])/len(df)} % of incorrect StatValue_USD.\")\n",
    "\n",
    "print(f\"\\nBefore cleaning: {100*count_diff(raw_data, cleaned_data, ['USD_per_KG'])/len(raw_data)} % of incorrect USD_per_KG.\")\n",
    "print(f\"Clean USD_per_KG: {100*count_diff(df, cleaned_data, ['USD_per_KG'])/len(df)} % of incorrect USD_per_KG.\")\n",
    "\n",
    "print(f\"\\nBefore cleaning: {100*count_diff(raw_data, cleaned_data, ['SenderNameEng'])/len(df)} % of misspelled SenderNameEng.\")\n",
    "print(f\"Clean strings: {100*count_diff(df, cleaned_data, ['SenderNameEng'])/len(df)} % of misspelled SenderNameEng.\")\n",
    "\n",
    "print(f\"\\nBefore cleaning: {100*count_diff(raw_data, cleaned_data, ['SenderCompanyKeywordsEng'])/len(raw_data)} % of misspelled SenderCompanyKeywordsEng.\")\n",
    "print(f\"Clean strings: {100*count_diff(df, cleaned_data, ['SenderCompanyKeywordsEng'])/len(df)} % of misspelled SenderCompanyKeywordsEng.\")\n",
    "\n",
    "print(f\"\\nBefore cleaning: {100*count_diff(raw_data, cleaned_data, ['RecipientNameEng'])/len(df)} % of misspelled RecipientNameEng.\")\n",
    "print(f\"Clean strings: {100*count_diff(df, cleaned_data, ['RecipientNameEng'])/len(df)} % of misspelled RecipientNameEng.\")\n",
    "\n",
    "print(f\"\\nBefore cleaning: {100*count_diff(raw_data, cleaned_data, ['RecipientCompanyKeywordsEng'])/len(raw_data)} % of misspelled RecipientCompanyKeywordsEng.\")\n",
    "print(f\"Clean strings: {100*count_diff(df, cleaned_data, ['RecipientCompanyKeywordsEng'])/len(df)} % of misspelled RecipientCompanyKeywordsEng.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean data by baseline-3:\n",
      "\n",
      "23 columns, 3087822 rows\n",
      "8.237331375797654 % of missing values.\n",
      "12.806612557330054 % of incorrect formats.\n",
      "6.832627807411976 % of misspellings.\n",
      "\n",
      "90.5699875187106 % of correct values.\n",
      "\n",
      "Average time to generate correct code: 269.3352068906015 s.\n",
      "Average # of revises to generate correct code: 1.4166666666666667.\n",
      "Accepted first-time codes: 17/24.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Clean data by baseline-3:\\n\")\n",
    "print(f\"{len(list(df.columns))} columns, {len(df)} rows\")\n",
    "print(f\"{100*df.isna().sum().sum()/(len(df)*len(df.columns))} % of missing values.\")\n",
    "print(f\"{100*count_diff(df, cleaned_data, num_cols)/(len(df)*len(num_cols))} % of incorrect formats.\")\n",
    "print(f\"{100*count_diff(df, cleaned_data, str_cols)/(len(df)*len(str_cols))} % of misspellings.\")\n",
    "print(f\"\\n{100-100*count_diff(df, cleaned_data, list(cleaned_data.columns))/(len(df)*len(cleaned_data.columns))} % of correct values.\")\n",
    "\n",
    "Time = [405.00571952201426, 364.8505232851021, 90.49188285390846, 230.93646942998748, 396.01469031802844, 239.7160882720491, 51.28350269200746, 647.606322239968, 362.9263410329586, 96.21659857500345, 981.0702107369434, 244.83681565499865, 203.46100543194916, 385.66700267698616, 58.433924220036715, 422.17109180195257, 365.48042021796573, 17.680476023000665, 22.339896818972193, 22.754380203899927, 170.66795389191248, 233.98927278094925, 392.30982334379967, 58.13455335004255]\n",
    "Iteration = [2, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 5, 1]\n",
    "\n",
    "total_time = np.sum(Time)\n",
    "total_iteration = np.sum(Iteration)\n",
    "first_time_cnt = 0\n",
    "for i in Iteration:\n",
    "  if Iteration[i] == 1:\n",
    "    first_time_cnt += 1\n",
    "print(f\"\\nAverage time to generate correct code: {total_time/len(Time)} s.\")\n",
    "print(f\"Average # of revises to generate correct code: {total_iteration/len(Iteration)}.\")\n",
    "print(f\"Accepted first-time codes: {first_time_cnt}/{len(Iteration)}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
